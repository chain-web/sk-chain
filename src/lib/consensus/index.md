使用pos + 分片实现共识

分片
按照账户的id进行分片
分片计划按照账户数量+节点数量进行动态调整
每个进行打包的节点在打包完成后要进行分片调整(分片调整需要计算和网路开销)
所有节点都有state tree，block header；对所有的block body数据进行分片存储，减少存储压力，后续会尽可能通过分片的方式来减少冗余存储


节点的分片策略是在节点运行之后进行动态变更的
所有符合下一分片规则的节点会一起订阅下一分片的消息，一旦下一订阅的节点数量大于限制数量，就会进行分片

因为DID生成是用的base58做的hash，所以最后字符串的每一位都有可能有58种可能

<!-- 扩张过程 -->
最开始都是o分片，然后根据自己的id最后一位，判断自己是否大于等于29，去订阅o-l或o-r
当o-l和o-r节点数量都到了一定量之后，进行分片
分片后的o-l再根据自己的倒数第二位是否大于等于29，去订阅o-l-l、o-l-r，依次类推，每往前进一位，分片数量*2

<!-- 缩量过程 -->
当前分片的节点数量小于64时，会跟同层节点合并，比如o-l-l-l 本来有100节点，但忽然降到60，就会导致o-l-l-r-？包括子分片在内的节点都回到o-l-l，直到o-l-l可以分为o-l-l-l和o-l-l-r
因为DID生成是随机的，所以不会存在非常严重的树不平衡的状态

至少保证在每个分片内有64个节点进行竞争打包
竞争打包是通过pubsub进行协商，协商的过程中如果单一竞争方大于128可以进行二分片



活跃度参数
因为完全依赖pos的话会有存在屯币的缺陷，需要引入活跃度作为打包节点选出的条件之一来平衡

 proof of contribute 对网络的贡献？ POC
 对网络的贡献 = ？，应该是一个动态计算的东西，随着时间的推移，它会动态改变
 全节点参与POC

 如果有分叉，就选择 contribute 最大的一个链作为主链

时空：、、、？
每条数据都是一个时间的函数，输入是元数据+时间，输出是输入时间对应的结果数据